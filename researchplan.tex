\section{Research Plan}

%\subsection{From Timed Automata to \framac}
%\label{sec:ta2framac}
%\input{automatatoframac}

\textcolor{blue}{The core outcome of this project consists of
  practical methods and a framework for combining formal, static, and dynamic analysis for embedded system software written in C and C++, as well as an open-source software implementation and two real-world case studies.  This section will detail these efforts.}

\subsection{DeepState and Automated Test Generation}
\label{sec:framac2deepstate}
\input{framactodeepstate}

\subsection{Other DeepState Extensions}

\paragraph{Bounded Model Checking:}
\input{cbmcplan}

\paragraph{Explicit-State Model Checking:}
\input{spinplan}

\paragraph{Timed Automata Model Skeleton Generation:}
As noted above, one of our core assumptions is that timed automata can
model the underlying protocols in many embedded systems.  However,
writing timed automata models using \uppaal~\cite{uppaal} and
\prism~\cite{KNP2011:CAV} is at present a skill only a small number of
embedded engineers have mastered.  In order to encourage more
engineers to make use of these powerful formalisms, we propose 1) to
enable DeepState to generate \emph{traces} of the annotations related
to timing that are covered during a run and 2) to build a tool to
combine and reconcile these traces into a skeleton model for \uppaal~\cite{uppaal} or
\prism~\cite{KNP2011:CAV} (as has been done to some extent for Java~\cite{liva2017extracting}).  The structure of code (function locations
of DeepState annotations) will be used to form the structure of the
model.  Additional annotations for, e.g. probabilities, may need to be
added if not present in the code annotations, though DeepState already
has a primitive support for expressing probabilities that we plan to extend.

% \paragraph{Other Tools:}  Galois Inc. has expressed strong interest in
% an (unpaid) ongoing research collaboration to integrate their C and
% C++ relevant tools into DeepState as well, to support our general vision.

\subsection{Pre-Trained Models to Provide Annotation Assistance}

NOTE THIS IS NOT YET EDITED TO BE WHAT WE NEED, JUST GRABS REFS

Modern LLMs have been pretrained on millions of source code tokens, thus these models have a strong understanding of code semantics 
and behavior. This can be seem with CodeBERT~\cite{codebert} embeddings outperforming prior work such as Code2Vec~\cite{code2vec} 
and TF-IDF~\cite{tfidf}, with the CodeBERT vectors capturing some
notion of semantic similarity rather than pure token match (as in techniques 
such as TF-IDF).  These training bases contain a large number of
tests, with many signals including naming and structure distinguishing
the test code within these corpuses, making
models ``aware'' of the tightly constrained nature of test code.
Thus one can generate entire test suites with a powerful model such as ChatGPT~\cite{gpttestgen, siddiq2023empirical}. 
Even smaller models, trained with this relationship~\cite{catlm, starcoder} show significant promise, generating tests that compile, execute successfully, and 
increase coverage.

The context of existing production code gives LLMs more to work with,
and the context of existing tests for production code may give LLMs
even more to work with: LLMs can be used to augment existing tests
with (better) oracles~\cite{OracleGEN}.  This is a particulary promising
application, since the tendency of oracle quality to lag behind code coverage
is an enduring and under-addressed problem in software testing~\cite{MindGap}.

Another critical problem in software testing is that while developers are
at least familliar with writing unit tests, few have experience in
writing property-based tests or fuzz-drivers~\cite{goldstein2022some}, a different task
that is often perceived as very difficult.  Generalizing oracle
generation from specific to parameterized unit tests is a potential
long-term solution to this problem, and there is already work underway
to generate fuzz drivers using LLMs~\cite{zhang2023understanding},
including by Google's OSS-Fuzz team, one of the most important
industrial fuzzing efforts~\cite{ossfuzzllm}.

\subsection{\textcolor{blue}{Dissemination of Software}}
\label{sec:software}

The proposed methods and framework will be incorporated into a usable
open source tool.
While individual software components will be developed and evaluated
in tandem with the research efforts described above, we dedicate a
task (Task T3 in Section~\ref{sec:workplan}) for consolidating all
these components in a practical, user-friendly software tool since
adoption by real-world users is a primary scientific goal of this project.
To maximize impact, the software will be made publicly available % on GitHub
using the MIT open source software license.
We are committed to making software open source as demonstrated by previously released % research
code \cite{mleplussoftware, bernalMLEToolIntegrated2012a, openbuildnetsoftware, nghiemOpenBuildNetFrameworkDistributed2016}.


\subsection{\textcolor{blue}{Case Studies}} % for Ecological Monitoring and Control}
\label{sec:case-study}

The above briefly introduces a number of problems that we know in advance must
be dealt with in order to enable a pathway for combining formal,
static, and dynamic analysis.    At heart, however, we aim to allow
case studies to prioritize our efforts, and
are certain that other challenges will arise during these efforts.
The studies informing this research are the embedded software of %wireless sensor nodes used in the Southwest Experimental Garden Array (SEGA)~\cite{ClaEtAl11,GhoEtAl2014,BelEtAl2015} and of 
wireless sensor nodes and mobile robots in the Distributed Sensing \& Computing Over Sparse Environments (DISCOVER) Platform.

\subsubsection{Overview of the DISCOVER Platform}
\label{sec:cast-study:discover}

DISCOVER %(Distributed Sensing and Computing Over Sparse Environments)
is a cyber-infrastructure testbed for remote, rural, and sparsely populated areas.
The project is funded by NSF and led by NAU, whose team includes co-PI Nghiem (co-PI of DISCOVER).
DISCOVER consists of a fabric of highly configurable Internet-of-Things (IoT) sensor nodes, autonomous and highly capable terrestrial robots and drones, and a heterogeneous wireless network.
DISCOVER sites will be located at the campuses of NAU, Navajo Technical University, and Clemsom University, as well as several remote sites.
The platform will enable focused research in many domains, including data science and machine learning, heterogeneous networked services, distributed computing and AI, control, autonomous robots, and in-network computation, among many others.
%
We will use DISCOVER for the case studies in this project.

\input{casestudysega}

\subsubsection{Case Study 2: Distributed Coordination in Multi-Robot Systems}
\label{sec:case-study-robots}

\input{casestudyrobots}

\subsection{Work Plan}

The detailed work plan and evaluation methods for our proposal are
described, including timelines, in the collaboration plan for this proposal.

%\label{sec:workplan}
%\input{workplan}

% \section{Contributions to Formal Methods and the Field}
% \label{sec:contributions}
% \input{contributions}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
