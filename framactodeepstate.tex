%\notetruong{We should update Figure 1 and relate this section to the steps in Figure 1.}
Applying DeepState to real embedded systems requires us to meet many challenges:

\begin{enumerate}[labelsep=3pt,leftmargin=12pt]
\item The \emph{specification} of correctness must be translated into an executable form.  To some extent, the existence of the \eacsl executable subset of \acsl, and libraries for runtime checking of properties satisfies this condition.  DeepState can support any C/C++ executable method of checking for correctness.  However, some executable specifications need to be modified to be efficiently handled when the DeepState back-end is a symbolic execution tool.  DeepState's nature as a test generation tool means that it supports constructs, such as {\tt Minimum}, {\tt Maximum}, and {\tt Pump}, not usually available in executable specifications.  Tailoring \eacsl usage for DeepState therefore requires a custom effort, including extending the semantics of executable specifications and optimizing the implementation for symbolic execution and fuzzing.  Finally, because our domain critically involves timing, we need to implement DeepState handling of (and \eacsl representations for) deadlines, and specification of function-level deadlines including arbitrary, specified, ``runtimes'' for code that operates via simulation rather than real hardware (or in symbolic execution).  Similar, but in some ways even more complex, challenges are posed by the ubiquity of \emph{interrupts} in embedded code, a problem addressed by very little previous work in fuzzing~\cite{song2019periscope}.
\item The \emph{assumptions} that control which tests are considered valid must be translated in the same way; normally, \eacsl simply translates these into further assertions (as pre-conditions to check at runtime), but in DeepState, we need to distinguish between {\tt ASSUME} failures (invalid tests) and {\tt ASSERT} failures (bugs). 
\item The inputs to a function must be translated into code controlling the input values that DeepState provides, including ranges and types.  When input types are simple, this process is straightforward; however, when functions take, e.g., arbitrarily sized arrays, linked lists, or other complex structures, this becomes a problem of constructing a test harness that (1) makes fuzzing and symbolic execution scalable but (2) uses large enough structures to expose subtle bugs.  Moreover, because DeepState supports strategies for input generation, such as forking concrete states for values too complex for symbolic execution using the {\tt Pump} construct, the translation must determine when such strategies are appropriate, and apply them.
\item In many cases, checking a single function may not be an effective way to detect faults; only a sequence of API calls can expose a problem in a system (e.g., that a function produce a state that causes another function to violate an invariant).  \acsl annotations provide enough information for a fully-automated translation to a harness enabling dynamic analysis in the case of proving properties of a single function, but not for groups of functions \footnote{There are some Frama-C plugins related to properties over groups of functions, but none apply to the most general form of state problems easily.}.  Moreover, even in cases where the violation of a specification can, in theory, be discovered without calling multiple functions, the state space may be too large to explore with a fuzzer or symbolic execution tool.  In such cases, exploring only states produced by valid call sequences has two benefits:  first, the space itself may be much smaller, and easier to explore, than the full set of possible input values.  Second, errors in this part of the input space are more important.  Even if a precondition is not sufficiently restrictive to guarantee correct behavior, if the ``bad'' inputs are never, in practice, generated by the functions that modify system state, the fault may not matter.  In cases where constructing a sufficiently exact precondition is difficult for engineers, such ``in-use'' verification may be the only avenue to system assurance.  We propose to let users annotate \emph{sets} of functions to be tested as an API-call-sequence group, extending recent work exploring this concept~\cite{blatter2018static,MetAcsl}.  
  \item Finally, DeepState and, in fact, general-purpose fuzzers such as AFL, have, to date, been exclusively (to our knowledge) used in what might be deemed conventional environments.  As recently noted, ``the tight coupling between hardware and firmware and the diversity found in embedded systems makes it hard to perform dynamic analysis on firmware'' and existing mainstream fuzzing tools offer almost no support to embedded developers for simulation and emulation~\cite{halucinator}.
\end{enumerate}

\begin{figure}[t]
  \hspace{-12pt}
  \begin{subfigure}{0.492\columnwidth}
  {\scriptsize
  \begin{code}
void update\_state(struct state\_t *s, uint64\_t bv) \{
  ASSUME(valid\_state(s));
  ASSUME(valid\_bv(bv));
  ...
\}

void process\_both\_sensor\_readings(struct state\_t *s) \{
  ASSUME(valid\_state(s)); 
  unit64\_t s1\_bv = acquire\_s1(), s2\_bv = acquire\_s2();   
  update\_state(s, s1\_bv);  update\_state(s, s2\_bv);  
\}
  
void process\_one\_sensor\_reading(struct state\_t *s) \{
  ASSUME(valid\_state(s)); 
  unit64\_t s1\_bv = acquire\_s1(); 
  update\_state(s, s1\_bv); 
\}
\end{code}
}
\end{subfigure}
\begin{subfigure}{0.492\columnwidth}
{\scriptsize
\begin{code}
struct state\_t *NewState() \{
  return DeepState\_Malloc(sizeof(struct state\_t));   
\}
    
TEST(SensorReading, UpdateNeverSlow) \{
  struct state\_t *s = NewState();
  DeepState\_Timeout(
    [\&]\{update\_state(s, DeepState\_UInt64());\},
    MAX\_EXPECTED\_UPDATE\_TIME);
\}

TEST(SensorReading, AvoidCrashes) \{
  struct state\_t *s = NewState();
  for(int i = 0; i < TEST\_LENGTH; i++) \{
    OneOf(
        [\&]\{process\_both\_sensor\_readings(s);\},
        [\&]\{process\_one\_sensor\_reading(s);\});
  \}
\} 
\end{code}
}
\end{subfigure}
  \caption{Sensor reading code and DeepState test harness}
  \label{fig:assumption}
  \end{figure}

  These goals require significant advances in three areas of dynamic analysis: first, a complete and principled approach to the problem of handling pre-conditions/assumption semantics, and second, an investigation of how to let fuzzers take advantage of the significant additional structure provided by property-based testing, including such assumptions.  Consider the code in Figure~\ref{fig:assumption}.  This defines two different tests of software that reads sensor values and incorporates them into a system state.  The two tests check two different properties:  {\tt UpdateNeverSlow} ensures that updating the sensor is never too slow.  It is checked, potentially, over \emph{all} valid inputs, not just ones produced by the actual sensor reading code in {\tt acquire\_s1} and {\tt acquire\_s2}.  The second test, {\tt AvoidCrashes} starts the system up in some valid state, and repeatedly either reads both sensors or only sensor one.  There is no explicit property, only the expectation that the system will not crash; tests can be executed using LLVM sanitizers to check for integer overflow and other undefined behavior.  Generating such harnesses automatically from \acsl specifications is a significant challenge, but our research agenda also includes solving problems that would appear even for manual harnesses.  For example, what is the proper semantics of the {\tt ASSUME} in {\tt update\_state}?  It depends on the test.  In {\tt UpdateNeverSlow}, a fuzzer will often generate an input value that violates the (possibly complex) requirements on valid states and sensor readings.  These invalid inputs should not be flagged as bugs (the default behavior of \eacsl), but instead the test should be abandoned without indicating that it failed.  However, in {\tt AvoidCrashes}, since we are not directly generating state values, that is, {\tt update\_state} is not an \emph{entry point} for the test, assumption violations should result in failed tests.  We aim to synthesize code to make assumptions automatically take on the proper semantics during test execution (including symbolic execution using constraint solvers).

  This point about preconditions/{\tt ASSUME} brings up a second point.  Preconditions, when they have an {\tt ASSUME} semantics, are fundamentally different than other branches in code.  A fuzzer will attempt to explore the behavior of branches in {\tt valid\_state} and {\tt valid\_bv} just as it explores branches in {\tt update\_state} or {\tt acquire}.  However, it is often possible to enumerate a vast number of paths that differentiate only invalid inputs, and so produce very little real testing.  A classic example is ``testing'' a file system by producing a huge variety of unmountable file system images, rather than actually executing POSIX operations~\cite{CFV08,AMAI}.  DeepState knows which branches are pre-conditions, and so can help avoid this problem.  In some fuzzers, this means prioritizing inputs to mutate based on whether they execute any code other than validity checks; but in fuzzers, such as Angora~\cite{angora} and Eclipser~\cite{eclipser}, that use lightweight constraint-solving to cover branches, the process can be more sophisticated.  We have begun discussions with the Eclipser team, and they confirm that identifying precondition code and devising suitable heuristics to handle it (e.g., never solve for a negation of a passed check) should improve performance.  Fuzzing of individual functions or sets of functions is a highly promising area: most fuzzing is applied at the whole-program level, where input generation can simply be too hard.  By focusing on a middle-ground between unit testing and whole-program fuzzing--using fuzzer technology to drive property-driven testing--the problem is made tractable.  Prioritizing paths that include more than just input validation is an explicit goal of, e.g., AFLFast~\cite{aflfast}, but it must work with an implicit definition based on path frequencies, while we have access to ground truth.  Given the complexity of state validity checks, there may be hard-to-reach---but uninteresting---ways to create invalid input; AFLFast will \emph{prioritize} such paths, while we will (correctly) avoid them.

  However, it is possible to be more aggressive with preconditions that flow directly from the test harness to a function.  Namely, in a large number of cases, it is possible to \emph{actually produce values satisfying a precondition from a fuzzer-chosen value} rather than simply abort the run.  This does not violate the semantics of the SUT; it merely transforms one arbitrary input into another, with a fixed mapping so that the fuzzer can still learn from the pattern of inputs, \emph{as transformed}.  Consider the simple case of ranges.  If a function begins with {\tt ASSUME ((input > 10) and (input < 256))} where {\tt input} is an integer parameter to the function, and this assumption takes place before any assignments to {\tt input} in the function, then in the case where the fuzzer directly generats a value for {\tt input}, we can replace the assumption with the code:

  {\tt if ((input <= 10) || (input >= 256)) input = (abs(input) \% 245) + 11}

  Rather than testing if {\tt input} is in a range, this simply maps values that violate the assumption into valid values, that could have been provided by the fuzzer.  In such simple cases, of course, the developer of the test harness could have written {\tt DeepState\_IntInRange(11, 245))}but when the values in an assumption are dynamically computed inside the called function and/or involve state values not visible to the test harness, or are simple more complex constraints than a simple range check, this is often impractical and sometimes almost impossible.  We propose to provide forms of {\tt ASSUME} that enable automatic mapping of inputs, without developer action (other than using our variants of ASSUME), using a mix of guaranteed transformations such as in the range case and ``search-based'' approaches that find a nearby value of an input that satisfies an assumption (particularly useful in case of, e.g., parity checks).

As far as we are aware, the problem of mapping inputs (rather than producing inputs) to satisfy a predicate has not been explored in the literature.  Note that a ``mapping'' may in the most general case be a \emph{search}: while also amenable to a solution like that above, a parity check can be satisfied simply by incrementing a fuzzer input byte until it satisfies a check.  This most-general approach may be useful in some cases, such as complex checksums with a small size, where a complete solution cannot be produced.  On average the time to produce a 16 bit checksum by brute force search from random bytes, for example, may be an acceptable overhead to fuzzing.

 We note that this approach to preconditions is not limited to DeepState and/or embedded systems; a manual transformation of this sort is given as essential advice for users of the Echidna smart-contract fuzzer \cite{echidna-advice}.  However, while Trail of Bits even provides an API for the simple range case, the complexity of correctly using the shift from assumption to mapping is such that it is seldom done for more complex cases.
  
  This effort also connects to a second fuzzing research thrust: making specification elements that do not correspond to simple code coverage visible to a fuzzer.  In this example, consider the {\tt DeepState\_Timeout} check (note that this itself is functionality we will develop as part of handing timing constraints in \framac and DeepState).  Unless we break down the timing analysis explicitly using a set of conditional branches, coverage-driven fuzzers cannot distinguish an execution that is very slow (close to violating the constraint) from one that has the minimum execution time possible.  We propose to make timing of such specified events visible to a fuzzer, by modifying coverage bit-vectors to incorporate bucketing of execution time.  Once we add such novel coverage measures, and introduce distinctions between coverage classes (as with preconditions), we will research how to balance competing priorities in more complex notions of coverage.  In addition to implicit execution properties such as timing, this can apply to coverage of data structures, for fuzzing data-driven code such as machine-learning algorithms, where much behavior is implicit---e.g., the route taken through a forest of decision trees.  In general we aim to extend the work~\cite{aflfast,lemieux2018fairfuzz,vuzzer,zhao2019send,aschermann2019redqueen}, that prioritizes certain program paths in an intelligent way, by exploiting our extended \acsl/\eacsl.

Finally, these elements must be tied to the problem of applying fuzzing and related methods in embedded-relevant execution environments.  We plan to investigate multiple potential solutions, initially focusing on integrating fuzzing with the HALucinator tool~\cite{halucinator} for virtualizing firmware via the Hardware Abstraction Layer, which is likely to add emulator-specific notions of coverage and path relevance.

% Additionally, in some cases, checking a single function may not be an effective way to detect faults; only a sequence of API calls can expose a problem in a system (e.g., that a function produce a state that causes another function to violate an invariant).  \acsl annotations provide enough information for a fully-automated translation to a harness enabling dynamic analysis in the case of proving properties of a single function, but this is no longer true for groups of functions.  Moreover, even in cases where the violation of a specification can, in theory, be discovered without calling multiple functions, the state space described by the precondition for a function may be too large to explore with a fuzzer or symbolic execution tool.  In such cases, exploring the space described by valid calls of other functions has two benefits:  first, the space described by a sequence of calls may be much smaller, and easier to explore, than the full set of possible input values to a function.  Second, errors in this portion of the input space are more clearly realistic scenarios.  Even if a precondition is not sufficiently restrictive to guarantee correct behavior, if the ``bad'' inputs are never, in practice, generated by the functions that modify system state, the fault may never appear in practice.  In cases where constructing a sufficiently exact precondition is difficult for engineers, such ``in-use'' verification may be the only avenue to system assurance; proof is impossible without a restrictive enough precondition, and dynamic methods may scale very poorly to, e.g., a large unstructured byte buffer such as a hash table.

% In principle, of course, users can write a new function (a kind of ``ghost function'' not really executed---in practice, a test harness) expressing the desired mix of API calls that preserve an invariant; however, this is a serious burden on a user, and users are likely to make errors in this task~\cite{CFV08,AMAI,scriptstospecs,groce2015verified,groce2018verified}; we instead propose to let users annotate (in an extension of \acsl) sets of functions to be tested as an API-call-sequence group.  E.g., annotating a set of file system functions ({\tt mkdir}, {\tt rmdir}, {\tt readdir}, etc.) as such a group could allow the automatic generation of a DeepState harness that checks for cases where a sequence of valid function calls can violate a precondition or cause a fault despite preconditions being satisfied.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
